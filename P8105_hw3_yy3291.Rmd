---
title: "Homework 3"
author: "Youssra Yemmas"
date: "2023-10-14"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(ggridges)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1
```{r}
data("instacart")
summary(instacart)
length(instacart)
nrow(instacart)
ncol(instacart)
skimr::skim(instacart)
```

From an initial summarizing look at the data instacart there are 1,384,617 observations of 15 variables with 4 variables that are categorical and 11 that are numerical. There also seems to be one binary variable, reordered, that corresponds to if an item is ordered again or not. Ther variables order day of the week and order hour of the day are interesting and show a median of 3 for day of the week meaning Wednesday is a day clients most often place their orders and with a median of 14 for hour of the day it seems most orders are places at 2 pm. 

# Problem 1 cont.-how many aisles are there and which aisles are the most items ordered from
```{r}
instacart |> 
  count(aisle) |> 
  arrange(desc(n))

instacart1_df =
instacart %>% 
  janitor::clean_names() %>% 
  group_by(aisle_id, aisle) %>% 
  summarize(n_obs = n())
```

We can see from the subsetted data frame that there are 134 aisles and using the toggle arrows when viewing the instacart1_df we can see that some of the aisles where most items are ordered from are the fresh vegetables, fresh fruits, packaged vegetables fruits, yoghurt and packaged cheese aisles. 

# Making a plot with number of items ordered in each aisle, filtering to aisles with more than 10000 items ordered 
```{r}
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point(aes(color = aisle)) + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1), legend.position = "right")

instacart1_df %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle_id = as.factor(aisle),
    aisle_id = fct_reorder(aisle, n)
  )
aisles_plot =
instacart1_df %>% 
  ggplot(aes(x = aisle_id, y = n_obs)) +
  geom_histogram(stat = "identity") +
  labs(title = "Number of Items Ordered in Each Aisle", x = "Name of Aisles", y = "Number of Items Ordered")
aisles_plot
```

# Making a table showing the most popular items in each of the aisles baking ingredients, dog food care, and packaged vegetables fruits including the number of times each is ordered
```{r}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()

```
This creates a data frame where we can toggle through and see that in the aisle baking ingredients the two most ordered items are Light Brown Sugar which was ordered 157 times and Pure Baking Soda which was ordered 140 times; in the aisle dog food care the two most ordered items in dog food care are Organix Grain Free Chicken & Vegetable Dog Food which was ordered 14 times and Organix Chicken & Brown Rice Recipe whcih was ordered 13 times and lastly in packaged vegetables fruits the two most ordered items are Organic Baby Spinach which was ordered 3324 times and Organic Raspberries which was ordered 1920 times. 

# Making a data frame showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week
```{r}
mean_hour_df = 
  instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable(digits = 2)
```
From the data we can see that the mean hour of the day at which the items Pink Lady Apples and Coffee Ice Cream are ordered each day of the week. 


# Problem 2
### First will need to focus on Overall Health Topic, including only responses from Excellent to Poor and organize the responses as a factor taking levels ordered from Poor to Excellent 
```{r}
data("brfss_smart2010")
summary(brfss_smart2010)
janitor::clean_names(brfss_smart2010)

brfss_smart2010_df =
brfss_smart2010 %>% 
  filter(Topic %in% c("Overall Health")) %>% 
  group_by(Response) %>% 
  mutate(
    Response = factor(Response, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"))
  ) %>% 
  arrange(Response)
```
### In 2002, which states were observed at 7 or more locations? What about in 2010?
```{r}
location_2002_df = 
  brfss_smart2010_df %>% 
  filter(Year == 2002) %>% 
  group_by(Locationabbr) %>% 
  summarize(
    n_obs = n(),
    n_locations = n_distinct(Locationdesc)
  ) %>% 
  filter(n_locations >= 7) %>% 
  select(Locationabbr)
 knitr::kable(location_2002_df)
 
# We can see that in 2002 the states Connecticut, Florida, Massachusetts, North Carolina, New Jersey and Pennsylvania were observed at 7 or mopre locations.
 
location_2010_df = 
  brfss_smart2010_df %>% 
  filter(Year == 2010) %>% 
  group_by(Locationabbr) %>% 
  summarize(
    n_obs = n(),
    n_locations = n_distinct(Locationdesc)
  ) %>% 
  filter(n_locations >= 7) %>% 
  select(Locationabbr)
 knitr::kable(location_2010_df)
 
# We can see that in 2010 the states California, Colorado, Florida, Massachusetts, Maryland, North Carolina, Nebraska, New Jersey, New York, Ohio, Pennsylvania, South Carolina, Texas and Washington were observed at 7 or more locations. It seems from 2002 to 2010 there was an increase in 8 more states. 
```

# Constructing a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).
```{r}
excellent_df = 
  brfss_smart2010_df %>% 
  filter(Response == "Excellent") %>% 
  select(Year, Locationabbr, Data_value) %>% 
  group_by(Locationabbr, Year) %>% 
  mutate(
    mean_data_value = mean(Data_value, na.rm = TRUE)
  )
excellent_plot =
  ggplot(excellent_df, aes(x = Year, y = mean_data_value, group = Locationabbr, color = Locationabbr)) +
  geom_line() +
  labs(title = "Spaghetti Plot of Mean Data Value Within Each State", x = "Year", Y = "Mean Values", color = "State") + 
  theme(legend.position = "right")
excellent_plot

# There seems to be a general downward with all of the States going down in Mean Data Values as the years go on. One state that stands out is West Virginia as it has a dramatic dip around 2005. 
```

# Making a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.
```{r}
nystate_2006_df = 
  brfss_smart2010_df %>% 
  filter(Locationabbr == "NY", Year == "2006") %>% 
  drop_na(Response)

nystate_2010_df = 
  brfss_smart2010_df %>% 
  filter(Locationabbr == "NY", Year == "2010") %>% 
  drop_na(Response)

nystate_0610_df =
  full_join(nystate_2006_df, nystate_2010_df)

nystate0610_plot = 
  ggplot(nystate_0610_df, aes(x = Response, y = Data_value, color = Locationabbr)) +
  geom_point() 
nystate0610_plot + facet_grid(Response ~ Year)
# There doesn't seem to ne much variety in the Overall health responses in NY State across the two years 2006 and 2010. Both Years see a tend of more values in the Fair, Good and Excellent Responses than the Poor response. 
```

# Problem 3 Starting with reading the NHANES Accelerometer Data and wrangling the data
```{r}
nhanes_acceler_data = 
  read_csv("./nhanes_accel.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = c(min1:min1440),
    names_to = "minute",
    names_prefix = "min",
    values_to = "mims"
  ) 

# Now I will read the demographic data and try to tidy it with the end goal in mind of merging both data sets with the first obvious issue being that this data set does not have the column names until 5 lines down so I have to skip those first 4 lines and then reconfigure the data to be non-numeric but rather factors that have multiple levels.
nhanes_demo_data = 
  read_csv("./nhanes_covar.csv", skip = 4) %>% 
  janitor::clean_names() %>% 
  mutate(
    sex = 
      case_match(sex, 1 ~ "Male", 2 ~ "Female"),
    sex = as.factor(sex),
    education =
      case_match(education, 1 ~ "Less than High School", 2 ~ " High School or Equivalent", 3 ~ "More than High School"),
    education = as.factor(education)
  )
```

# Attempting to Merge the two data sets
The aim for the final data frame is that all originally observed variables are included; exclude participants less than 21 years of age, and those with missing demographic data; and encode data with reasonable variable classes (i.e. not numeric, and using factors with the ordering of tables and plots in mind).
```{r}
final_nhanes_df =
  full_join(nhanes_acceler_data, nhanes_demo_data) %>% 
  filter(age > 20) %>% 
  drop_na(sex, age, bmi, education)
is.factor(final_nhanes_df$sex)
is.factor(final_nhanes_df$education)
skimr::skim(final_nhanes_df)
```

# Producing a reader-friendly table for the number of men and women in each education category
```{r}
sex_edu_table = 
  final_nhanes_df %>% 
  select(sex, education) %>% 
  group_by(sex, education) %>% 
  summarize(count = n()) %>% 
  knitr::kable()

sex_edu_table
# There seems to be more Men than Women who have a High School or Equivalent Degree (50400 and 33120 respectively), there is about the same number of Men and Women who have Less Than a High School degree (38880 and 40320 respectively) but proportionally there seems to be a greater proportion of women who have less than a high school degree. In terms of higher education there is more women who have more than a high school degree. 

```

# A plot of the age distribution for men and women in each education category
```{r}
sex_edu_age_plot = 
  ggplot(final_nhanes_df, aes(x = age, fill = sex)) +
  geom_density(alpha = .5, adjust = .5) +
  labs(
    title = "Age Distribution for Men and Women in Each Education Category",
    x = "Age from Participants who are 21 and Older ",
    y = "Density", 
    fill = "Sex"
  ) + 
  facet_grid(.~education, labeller = label_both) +
  scale_x_continuous(
    breaks = c(10, 20, 30, 40, 50, 60, 70, 80)
  )
           
sex_edu_age_plot 
# There seems to be a lot of peaks in the distribution for all of the educational categories for both men and women. In the High school or equivalent educational category it seems for Women older age groups of around 60-70 years are predominant whereas for men it is more concentrated in younger age groups. In the Less than high school educational category there is a peak of 40-50 years old for men and one around 70 years old for women. In the More than High School Educational Category it seems both mean and women have the same peak in the younger age groups between 20-30.Interestingly, the distributions for both sexes in the Less than High School category and the More than High School category are skewed concordantly whereas for the High School or Equivalent educational category the distributions are skewed oppositionaly with the Male distribution being almost left skewed and the female one being right skewed. 
```

# Creating a total activity variable
```{r}
nhanes_total_act_df = 
  final_nhanes_df %>% 
  group_by(seqn) %>% 
  mutate(
    total_activity = sum(mims)
  )
```

# Plotting the total activity
```{r}
total_activity_plot = 
  ggplot(nhanes_total_act_df, aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = .5) +
  geom_smooth(se = FALSE) +
  facet_grid(.~ education, labeller = label_both) +
  labs(
    title = "Total Activity of Participants by Age and Education",
    x = "Age from Participants 21 and Older",
    y = "Total Activity"
  )

total_activity_plot

# This Plot shows some interesting variability by Education. It seems that for participants who have more than a high school education there is a general even mapping of the activity between both sexes except when it gets to the 60 age group they diverge quite dramatically with women getting in much more activity than men. For the Less than high school educational category there is a general downward trend in activity as participants get older and contrary to the more than high school educational category the participants diverge again around the 6o age group but this time men are getting much more activity than women when looking at the trend line. Lastly, there seems to be a similar trend line for both sexes in the High School or Equivalent educational category with similar peaks and dips between the sexes it just seems like men are lagging slightly behind in activty than women. 
```

# Trying to Make another variable that describes the 24 hour course of activity
```{r}
is.numeric(nhanes_total_act_df$minute)
twentyfour_hr_df = 
  nhanes_total_act_df %>% 
  group_by(seqn) %>% 
  mutate(
    minute = as.numeric(minute),
    activity_by_hr = mims/60, 
    hour = minute/60
  )

twentyfour_hr_plot =
  ggplot(twentyfour_hr_df, aes(x = hour, y = activity_by_hr, color = sex)) +
  geom_point(alpha = .1) +
  geom_smooth(se = FALSE) +
  facet_grid(.~ education, labeller = label_both) +
  scale_x_continuous(
    breaks = c(0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24)
  ) +
  labs(
    title = "Activity Spread by Hour over 24 Hrs by Education and Sex",
    x = "Hour",
    y = "Activity by Hour"
  ) +
  viridis::scale_fill_viridis(discrete = TRUE) +
  theme(legend.position = "bottom")

twentyfour_hr_plot
  
# Looking at the trend lines there seems to be a similar distribution of activity across the 24 hr period of a day between both sexes and all three educational categories. Which makes sense considering most people are asleep during the night. Interestingly, there seem to be a lot of outliers in the More than highschool educational category in the later part of the day. 
```
